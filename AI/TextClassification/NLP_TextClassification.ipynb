{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* enable  Cloud Natural Language API <br>\n",
    "*  Create an API Key <br>\n",
    "  Navigation menu > APIs & services > Credentials >> Create credentials >> API key <br>\n",
    "  copy the key you just generated <br>\n",
    " ```shell  export API_KEY=<YOUR_API_KEY>```\n",
    "* in cloud shell environment <br>\n",
    "```shell\n",
    "nano request.json \n",
    "{\n",
    "  \"document\":{\n",
    "    \"type\":\"PLAIN_TEXT\",\n",
    "    \"content\":\"A Smoky Lobster Salad With a Tapa Twist. This spin on the Spanish pulpo a la gallega skips the octopus, but keeps the sea salt, olive oil, pimentón and boiled potatoes.\"\n",
    "  }\n",
    "}\n",
    "```\n",
    "* send request to API <br>\n",
    "```shell\n",
    "curl \"https://language.googleapis.com/v1/documents:classifyText?key=${API_KEY}\" \\\n",
    "  -s -X POST -H \"Content-Type: application/json\" --data-binary @request.json\n",
    "```\n",
    "output like { categories: [ { name: '/Food & Drink/Cooking & Recipes', confidence: 0.85 }, { name: '/Food & Drink/Food/Meat & Seafood', confidence: 0.63 } ] }  <br>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying a large text dataset\n",
    "```shell\n",
    "gsutil cat gs://cloud-training-demos-text/bbc_dataset/entertainment/001.txt\n",
    "```\n",
    "create dataset :  news_classification_dataset <br>\n",
    "create table :  article_data <br>\n",
    "schema table :  article_text:STRING, category:STRING , confidence:FLOAT <br>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying news data and storing the result in BigQuery\n",
    "iam \n",
    "```shell\n",
    "gcloud iam service-accounts create my-account --display-name my-account\n",
    "gcloud projects add-iam-policy-binding $PROJECT --member=serviceAccount:my-account@$PROJECT.iam.gserviceaccount.com --role=roles/bigquery.admin\n",
    "gcloud iam service-accounts keys create key.json --iam-account=my-account@$PROJECT.iam.gserviceaccount.com\n",
    "export GOOGLE_APPLICATION_CREDENTIALS=key.json\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile classify-text.py \n",
    "from google.cloud import storage, language_v1, bigquery\n",
    "# Set up our GCS, NL, and BigQuery clients\n",
    "storage_client = storage.Client()\n",
    "nl_client = language_v1.LanguageServiceClient()\n",
    "# TODO: replace YOUR_PROJECT with your project id below\n",
    "bq_client = bigquery.Client(project='YOUR_PROJECT')\n",
    "dataset_ref = bq_client.dataset('news_classification_dataset')\n",
    "dataset = bigquery.Dataset(dataset_ref)\n",
    "table_ref = dataset.table('article_data') # Update this if you used a different table name\n",
    "table = bq_client.get_table(table_ref)\n",
    "# Send article text to the NL API's classifyText method\n",
    "def classify_text(article):\n",
    "        response = nl_client.classify_text(\n",
    "                document=language_v1.types.Document(\n",
    "                        content=article,\n",
    "                        type_='PLAIN_TEXT'\n",
    "                )\n",
    "        )\n",
    "        return response\n",
    "rows_for_bq = []\n",
    "files = storage_client.bucket('cloud-training-demos-text').list_blobs()\n",
    "print(\"Got article files from GCS, sending them to the NL API (this will take ~2 minutes)...\")\n",
    "# Send files to the NL API and save the result to send to BigQuery\n",
    "for file in files:\n",
    "        if file.name.endswith('txt'):\n",
    "                article_text = file.download_as_bytes()\n",
    "                nl_response = classify_text(article_text)\n",
    "                if len(nl_response.categories) > 0:\n",
    "                        rows_for_bq.append((str(article_text), str(nl_response.categories[0].name), nl_response.categories[0].confidence))\n",
    "print(\"Writing NL API article data to BigQuery...\")\n",
    "# Write article text + category data to BQ\n",
    "errors = bq_client.insert_rows(table, rows_for_bq)\n",
    "assert errors == []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- bigquery \n",
    "SELECT\n",
    "  category,\n",
    "  COUNT(*) c\n",
    "FROM\n",
    "  `news_classification_dataset.article_data`\n",
    "GROUP BY\n",
    "  category\n",
    "ORDER BY\n",
    "  c DESC\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![queryresult](queryresult.png)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
